---
title: "NEH Grants Data Analysis"
author: "Brian A. Danielak"
format: 
  html:
    toc: true
editor: visual
---

# Loading and Cleaning the Data

## Loading Necessary Libraries

```{r}
# #| echo: false
# #| message: false
library(tidycensus)
library(tidyverse)
library(vroom)
library(xml2)

# Load US Census API Key (http://api.census.gov/data/key_signup.html)
# We use `read_lines` so as not to get a trailing newline character when reading the file
census_api_key <- readr::read_lines(
  "../us-census-api-key.txt",
  n_max = 1  
)
```

## Loading Grant Data from Downloaded XML

```{r}
load_grants_from_raw_xml <- function(path_to_xml = "../data-raw/NEH_Grants2000s_Flat/NEH_Grants2000s_Flat.xml") {
  
  # First, we check if the rectangularized file already exists.
  if (file.exists("../data-cleaned/grants-data-cleaned.tsv")) {
    
    # If it exists, we load it and return it
    grants_cleaned <- vroom::vroom("../data-cleaned/grants-data-cleaned.tsv")
    return(grants_cleaned)
  
  # Otherwise, we do the expensive thing and load the data from XML
  } else {
      grants_raw <- xml2::read_xml(path_to_xml) |> 
        xml2::as_list()
      
      grants_tibble <- grants_raw$Grants |> 
        lapply(unlist) |> 
        dplyr::bind_rows()
  
      # Write the rectangularized data out so we can load *it* next time
      grants_tibble |> 
        dplyr::transmute_all(unlist) |> 
        vroom::vroom_write("../data-cleaned/grants-data-cleaned.tsv")
      
      # Load the rectangularized data from file 
      # (`vroom` will help infer column types automatically on load.)
      grants_cleaned <- vroom::vroom("../data-cleaned/grants-data-cleaned.tsv") 
      return(grants_cleaned)
  }
}

# I downloaded and unzipped the 2000s grant data
# https://securegrants.neh.gov/open/data/NEH_Grants2000s_Flat.zip
grants_2000s <- load_grants_from_raw_xml()
```

# Exploratory Data Analysis

First, let's get an idea of what the data looks like.

```{r}
grants_2000s |> 
  dplyr::glimpse()
```

Which programs represent the most grants awarded?

```{r}
grants_2000s |> 
  dplyr::count(Program) |> 
  arrange(desc(n))
```

## Visualizing the Distribution of Total Amounts

What happens if we combine the Award Outright with the Award Matching to get a sense of the total distribution of award amounts?

```{r}
grants_2000s |> 
  mutate(TotalAmount = AwardOutright + AwardMatching) |> 
  ggplot() +
  geom_histogram(aes(x = TotalAmount))
```

## 

Hmm, that's strange.
It looks like we have a skewed distribution with a long right tail.
The histogram suggests there may be just a few awards totaling \$4,000,000 or more.
Let's look at how many awards exceed \$1,000,000.

```{r}
exceed_1_million_in_funding <- grants_2000s |> 
  mutate(TotalAmount = AwardOutright + AwardMatching) |> 
  filter(TotalAmount > 1e6)

dim(exceed_1_million_in_funding)[1]
```

Looks like there are 179 projects that exceed \$1 million in funding.
What happens if we look at *their* distribution?

```{r}
exceed_1_million_in_funding |> 
  ggplot() + 
  geom_histogram(aes(x = TotalAmount))
```

There seems to be a cluster of about 40 projects whose total funding falls at around \$1.5 million.

## Exploring Grant Duration

How long do grants typically last?

```{r}
grants_2000s |> 
  mutate(Duration = EndGrant - BeginGrant) |> 
  ggplot() +
  geom_histogram(aes(x = Duration)) +
  xlab("Duration (Days)") + 
  ylab("Count")
```

Seems like most grants have a duration under 2100 days, which is roughly six years.
Let's zoom in on the region between 0 and 2000 days.

```{r}
grants_2000s |> 
  mutate(Duration = EndGrant - BeginGrant) |> 
  filter(Duration <= 2000) |> 
  ggplot() +
  geom_histogram(aes(x = Duration), binwidth = 20) +
  geom_vline(xintercept = 365, color = "red", alpha = 0.5) +
  xlab("Duration (Days)") + 
  ylab("Count")
```

Perhaps unsurprisingly, the most common award duration is 365 days (line shown in red), or one year.

## Comparing Grant Duration to Total Amount Granted

Is there a relationship between how long a grant lasts and how much money is granted?

```{r}
grants_2000s |> 
  mutate(
    TotalAmount = AwardOutright + AwardMatching,
    Duration = EndGrant - BeginGrant
  ) |> 
  ggplot() +
  geom_point(aes(Duration, TotalAmount), alpha = 0.2) + 
  labs(
    x = "Duration (days)",
    y = "Total Amount"
  )
```

There's an interesting vertical band just past 1750 days, where grants of the same duration have fairly different funding amounts.
Let's explore that.

```{r}
grants_2000s |> 
  mutate(
    TotalAmount = AwardOutright + AwardMatching,
    Duration = EndGrant - BeginGrant
  ) |> 
  filter(Duration >= 1500 & Duration <= 2000) |> 
  ggplot() +
  geom_point(aes(Duration, TotalAmount), alpha = 0.2) + 
  geom_vline(xintercept = 1825, color = "red", alpha = 0.5)
  labs(
    x = "Duration (days)",
    y = "Total Amount"
  )
```

ðŸ‘† This graph shows us the wide variation in funding for grants that last approximately 5 years.

## What happens when we break down the discipline category by splitting on semicolons?

# RQ 1 - What's the mean funding amount by state? (Sort descending)

## Loading Data with `tidycensus`

```{r}
#| message: false
census_api_key <- readr::read_lines(
  "../us-census-api-key.txt",
  n_max = 1  
)

load_census_data <- function(census_data = "../data-cleaned/2010-census.tsv") {
  # We don't want to keep hitting the API every time our code runs, 
  # so if we already have the data, vroom it and return it.
  if (file.exists(census_data)) {
    return(vroom::vroom(census_data))
  } else {
    # Otherwise, we hit the API for it, vroom it, and return it
    get_decennial(
      geography = "state", 
      variables = "P001001",
      year = 2010
    ) |> vroom::vroom_write(census_data)
    return(vroom::vroom(census_data))
  }
}


# I Had to pick a year for the 2000s NEH grant data,
# so I settled on 2010. I also could have done 2000
state_populations <- load_census_data()

states <- state_populations |> 
  rename(
    census_state = NAME,
    population =  value
  ) |>
  pull()
```

Unfortunately, R's built-in `state` dataset only has data for the 50 states and not other US territories/regions.
So, let's find out which census regions/territories don't exist in R's built-in set.
Then we can add them.

```{r}
# First we grab and store all the unique values in the Census states.
census_state_names <- states |> 
  select(census_state) |> 
  pull() |> 
  unique()

# Then, we use them to index into state abbreviations to find out which 
# aren't in R's built-in dataset
states_in_census_but_not_in_built_in_dataset <- is.na(state.abb[match(census_state_names, state.name)])

census_state_names[states_in_census_but_not_in_built_in_dataset]
```

OK, now that we know those states, we can augment the existing state dataset with those abbreviations.

```{r}
census_states <- state.name

# This is a trick that lets us more easily index state names by their abbreviations
names(census_states) <- state.abb

# Now we can add DC and Puerto Rico
census_states <- c(
  census_states, 
  DC = "District of Columbia",
  PR = "Puerto Rico"
)
```

Next, we use our newly-augmented `census_states` to see how many grants would get dropped because we don't have US Census populations for them.

```{r}
grants_with_no_population_info <- grants_2000s |> 
  filter(!(InstState %in% names(census_states))) |> 
  select(InstState)

dim(grants_with_no_population_info)[1]
percentage_of_grants_without_population_data <- dim(grants_with_no_population_info)[1] / dim(grants_2000s)[1] * 100

percentage_of_grants_without_population_data
```

The original dataset had `r grants_2000s |> dim[2]` rows.
The filtered dataset has `r grants_2000s |> filter(InstState %in% census_states`. So, we've dropped

## Unfinished Thoughts

We can use `DisciplineCount` to determine how many fields to split the Discipline into.

# Sources

-   StackOverflow: Converting a State Name to State Abbreviation: [*https://stackoverflow.com/questions/5411979/state-name-to-abbreviation*](https://stackoverflow.com/questions/5411979/state-name-to-abbreviation){.uri}
-   Analyzing US Census Data: Methods, Maps, and Models in R: [*https://walker-data.com/census-r/an-introduction-to-tidycensus.html?q=key#getting-started-with-tidycensus*](https://walker-data.com/census-r/an-introduction-to-tidycensus.html?q=key#getting-started-with-tidycensus){.uri}
-   US Census API Key Request Form: [*http://api.census.gov/data/key_signup.html*](http://api.census.gov/data/key_signup.html){.uri}
